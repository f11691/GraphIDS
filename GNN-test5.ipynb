{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4e5d9-565c-4852-b942-b8975989d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Best Version###\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class GNN_Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels):\n",
    "        super(GNN_Autoencoder, self).__init__()\n",
    "        self.encoder_conv = GCNConv(in_channels, hidden_channels)\n",
    "        self.encoder_conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.decoder_conv = GCNConv(out_channels, hidden_channels)\n",
    "        self.decoder_conv2 = GCNConv(hidden_channels, in_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.encoder_conv(x, edge_index))\n",
    "        x = F.relu(self.encoder_conv2(x, edge_index))\n",
    "        x = F.relu(self.decoder_conv(x, edge_index))\n",
    "        x = self.decoder_conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def pad_features(x, max_features):\n",
    "    pad_size = max_features - x.shape[1]\n",
    "    if pad_size > 0:\n",
    "        padding = torch.zeros((x.shape[0], pad_size), dtype=x.dtype)\n",
    "        x = torch.cat([x, padding], dim=1)\n",
    "    return x\n",
    "\n",
    "def generate_graph_data(json_file, max_features):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data_list = json.load(file)\n",
    "    for item in data_list:\n",
    "        edge_index = torch.tensor(item['data']['edge_index'], dtype=torch.long)\n",
    "        if edge_index.dim() == 1 or edge_index.size(0) == 1:\n",
    "            edge_index = edge_index.view(2, -1)\n",
    "        x = torch.tensor(item['data']['x'], dtype=torch.float)\n",
    "        x_padded = pad_features(x, max_features)\n",
    "        label = item.get('label')\n",
    "        yield Data(x=x_padded, edge_index=edge_index), label\n",
    "\n",
    "def find_max_features(json_dir):\n",
    "    max_features = 0\n",
    "    for json_file in Path(json_dir).glob('*.json'):\n",
    "        with open(json_file, 'r') as file:\n",
    "            data_list = json.load(file)\n",
    "        for item in data_list:\n",
    "            x = torch.tensor(item['data']['x'], dtype=torch.float)\n",
    "            max_features = max(max_features, x.size(1))\n",
    "    return max_features\n",
    "\n",
    "def evaluate_model_with_threshold(model, criterion, device, test_data_loader, test_labels, threshold):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    graph_level_errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_data_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            loss = criterion(output, batch.x)\n",
    "            total_loss += loss.item()\n",
    "            batch_errors = torch.mean((output - batch.x) ** 2, dim=1)\n",
    "            if hasattr(batch, 'batch'):\n",
    "                for i in range(batch.num_graphs):\n",
    "                    graph_error = batch_errors[batch.batch == i].mean().item()\n",
    "                    graph_level_errors.append(graph_error)\n",
    "            else:\n",
    "                graph_level_errors.append(batch_errors.mean().item())\n",
    "    \n",
    "    predicted_labels = [1 if error > threshold else 0 for error in graph_level_errors]\n",
    "    precision = precision_score(test_labels, predicted_labels)\n",
    "    recall = recall_score(test_labels, predicted_labels)\n",
    "    f1 = f1_score(test_labels, predicted_labels)\n",
    "    avg_reconstruction_error = sum(graph_level_errors) / len(graph_level_errors)\n",
    "\n",
    "    \n",
    "    predicted_labels = [1 if error > threshold else 0 for error in graph_level_errors]\n",
    "    \n",
    "    # Calculate True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN)\n",
    "    tp = sum(t == 1 and p == 1 for t, p in zip(test_labels, predicted_labels))\n",
    "    tn = sum(t == 0 and p == 0 for t, p in zip(test_labels, predicted_labels))\n",
    "    fp = sum(t == 0 and p == 1 for t, p in zip(test_labels, predicted_labels))\n",
    "    fn = sum(t == 1 and p == 0 for t, p in zip(test_labels, predicted_labels))\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    accuracy = (tp + tn) / (len(test_labels))\n",
    "    \n",
    "    # Calculate AUC \n",
    "    if tp + fn > 0 and tn + fp > 0:\n",
    "      auc = roc_auc_score(test_labels, predicted_labels)\n",
    "    else:\n",
    "      auc = 0.5 \n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_labels, predicted_labels)\n",
    "    auc = roc_auc_score(test_labels, predicted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (AUC = %0.4f)' % auc)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    # plt.show()  # This will display the plot\n",
    "\n",
    "    plt.savefig('roc_curve.pdf', format=\"pdf\", dpi=300, bbox_inches='tight') \n",
    "    return total_loss / len(test_data_loader), precision, recall, f1, avg_reconstruction_error, auc, accuracy\n",
    "\n",
    "def main():\n",
    "    json_dir = 'json2'  # Adjust path as needed\n",
    "    test_json_dir = 'json4'  # Adjust path as needed\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    max_features = max(find_max_features(json_dir), find_max_features(test_json_dir))\n",
    "\n",
    "    # Parameters from optimization\n",
    "    learning_rate = xxx\n",
    "    weight_decay = xxx\n",
    "    threshold = xxx\n",
    "    out_channels = xxx\n",
    "    hidden_channels = xxx\n",
    "\n",
    "    model = GNN_Autoencoder(in_channels=max_features, out_channels=out_channels, hidden_channels=hidden_channels).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Prepare training data\n",
    "    training_dataset = []\n",
    "    for json_file in Path(json_dir).glob('*.json'):\n",
    "        for data, _ in generate_graph_data(json_file, max_features):  # Labels not used in autoencoder training\n",
    "            training_dataset.append(data)\n",
    "    training_data_loader = DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(5):  # Assuming a small number of epochs for demonstration\n",
    "        model.train()\n",
    "        for data in training_data_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = model(data.x, data.edge_index)\n",
    "            loss = criterion(reconstructed, data.x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Prepare test data\n",
    "    test_dataset, test_labels = [], []\n",
    "    for json_file in Path(test_json_dir).glob('*.json'):\n",
    "        for data, label in generate_graph_data(json_file, max_features):\n",
    "            test_dataset.append(data)\n",
    "            test_labels.append(label if label is not None else 0)\n",
    "    test_data_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "    # Evaluate the model\n",
    "\n",
    "\n",
    "    test_loss, precision, recall, f1, avg_reconstruction_error, auc, accuracy = evaluate_model_with_threshold(\n",
    "        model, criterion, device, test_data_loader, test_labels, threshold)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Average Reconstruction Error: {avg_reconstruction_error:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "  \n",
    "    print(\"Best model saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d772a-32f0-48eb-8db7-b2d7307191ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f4c9d-6c68-4f62-8591-95b60b44b914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnomalyTest",
   "language": "python",
   "name": "anomalytest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
