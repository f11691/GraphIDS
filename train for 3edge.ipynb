{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44fe54ce-fc8a-422d-8966-65ffa01bf202",
   "metadata": {},
   "source": [
    "# Create the train datastracture for 3 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea8e368-d9d2-41c7-9be8-b08b5a03ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3887039/3618146485.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Timestamp'] = pd.to_datetime(filtered_data['Timestamp'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered and temporally ordered data saved to 'filtered_train_3edge.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the features to keep\n",
    "features_to_keep = [\n",
    " ######list of selected features####\n",
    "]\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('train_data.csv')  # Replace 'your_data.csv' with your actual file name\n",
    "\n",
    "# Keep only the specified features\n",
    "filtered_data = data[features_to_keep]\n",
    "\n",
    "# Convert 'Timestamp' to datetime\n",
    "filtered_data['Timestamp'] = pd.to_datetime(filtered_data['Timestamp'])\n",
    "\n",
    "# Order the data by 'Timestamp'\n",
    "filtered_data = filtered_data.sort_values(by='Timestamp')\n",
    "\n",
    "# Save the temporally ordered data to a new file\n",
    "filtered_data.to_csv('filtered_train_3edge.csv', index=False)\n",
    "\n",
    "print(\"Filtered and temporally ordered data saved to 'filtered_train_3edge.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040f6f32-797b-45c9-a068-8992f624b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution:\n",
      "Label\n",
      "1    1978039\n",
      "0    1208711\n",
      "Name: count, dtype: int64\n",
      "The CSV contains label '1'.\n"
     ]
    }
   ],
   "source": [
    "#check for inside of csv (just for test, no need for run)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"filtered_train_3edge.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if the label column contains '1'\n",
    "label_column = 'Label'  # Replace with the actual label column name if different\n",
    "if label_column in df.columns:\n",
    "    label_distribution = df[label_column].value_counts()\n",
    "    print(\"Label Distribution:\")\n",
    "    print(label_distribution)\n",
    "\n",
    "    if 1 in label_distribution.index:\n",
    "        print(\"The CSV contains label '1'.\")\n",
    "    else:\n",
    "        print(\"The CSV does NOT contain label '1'.\")\n",
    "else:\n",
    "    print(f\"'{label_column}' column not found in the CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9f8f1-6def-4b93-9f9a-584674374aca",
   "metadata": {},
   "source": [
    "# created hourly graph with 3 edges from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d04037-94a6-473c-b44b-f47c30dbbee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour 0:\n",
      "Label\n",
      "0    558\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 0 saved to 3ed_trai_h_graphs/test_graph_hour_0.gpickle\n",
      "Hour 1:\n",
      "Label\n",
      "0    475\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 1 saved to 3ed_trai_h_graphs/test_graph_hour_1.gpickle\n",
      "Hour 2:\n",
      "Label\n",
      "0    551\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 2 saved to 3ed_trai_h_graphs/test_graph_hour_2.gpickle\n",
      "Hour 3:\n",
      "Label\n",
      "0    1251\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 3 saved to 3ed_trai_h_graphs/test_graph_hour_3.gpickle\n",
      "Hour 4:\n",
      "Label\n",
      "0    1513\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 4 saved to 3ed_trai_h_graphs/test_graph_hour_4.gpickle\n",
      "Hour 5:\n",
      "Label\n",
      "0    1397\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 5 saved to 3ed_trai_h_graphs/test_graph_hour_5.gpickle\n",
      "Hour 6:\n",
      "Label\n",
      "0    1468\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 6 saved to 3ed_trai_h_graphs/test_graph_hour_6.gpickle\n",
      "Hour 7:\n",
      "Label\n",
      "0    1382\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 7 saved to 3ed_trai_h_graphs/test_graph_hour_7.gpickle\n",
      "Hour 8:\n",
      "Label\n",
      "0    1503\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 8 saved to 3ed_trai_h_graphs/test_graph_hour_8.gpickle\n",
      "Hour 9:\n",
      "Label\n",
      "0    1566\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 9 saved to 3ed_trai_h_graphs/test_graph_hour_9.gpickle\n",
      "Hour 10:\n",
      "Label\n",
      "0    1702\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 10 saved to 3ed_trai_h_graphs/test_graph_hour_10.gpickle\n",
      "Hour 11:\n",
      "Label\n",
      "0    1652\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 11 saved to 3ed_trai_h_graphs/test_graph_hour_11.gpickle\n",
      "Hour 12:\n",
      "Label\n",
      "0    1847\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 12 saved to 3ed_trai_h_graphs/test_graph_hour_12.gpickle\n",
      "Hour 13:\n",
      "Label\n",
      "0    1390\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 13 saved to 3ed_trai_h_graphs/test_graph_hour_13.gpickle\n",
      "Hour 14:\n",
      "Label\n",
      "1    26290\n",
      "0     4073\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 14 saved to 3ed_trai_h_graphs/test_graph_hour_14.gpickle\n",
      "Hour 15:\n",
      "Label\n",
      "1    366353\n",
      "0    159638\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 15 saved to 3ed_trai_h_graphs/test_graph_hour_15.gpickle\n",
      "Hour 16:\n",
      "Label\n",
      "1    353926\n",
      "0    285549\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 16 saved to 3ed_trai_h_graphs/test_graph_hour_16.gpickle\n",
      "Hour 17:\n",
      "Label\n",
      "1    354314\n",
      "0    213991\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 17 saved to 3ed_trai_h_graphs/test_graph_hour_17.gpickle\n",
      "Hour 18:\n",
      "Label\n",
      "1    359961\n",
      "0    227323\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 18 saved to 3ed_trai_h_graphs/test_graph_hour_18.gpickle\n",
      "Hour 19:\n",
      "Label\n",
      "1    388078\n",
      "0    215716\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 19 saved to 3ed_trai_h_graphs/test_graph_hour_19.gpickle\n",
      "Hour 20:\n",
      "Label\n",
      "1    129117\n",
      "0     84166\n",
      "Name: count, dtype: int64\n",
      "Test graph for hour 20 saved to 3ed_trai_h_graphs/test_graph_hour_20.gpickle\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def create_test_graphs_edge_labels(df, output_dir):\n",
    "    \"\"\"\n",
    "    Split the DataFrame into hourly slices and create graphs for each slice.\n",
    "    Each edge gets a valid label (e.g., 0 or 1) read from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with temporal data.\n",
    "        output_dir (str): Directory to save the graphs.\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Group the DataFrame into hourly slices using the datetime index.\n",
    "    # (Assumes the DataFrame index is already a DateTimeIndex)\n",
    "    time_slices = [g for _, g in df.groupby(pd.Grouper(freq='H'))]\n",
    "    \n",
    "    for slice_index, slice_df in enumerate(time_slices):\n",
    "        if slice_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Print value counts of the 'Label' column in this time-slice.\n",
    "        print(f\"Hour {slice_index}:\")\n",
    "        print(slice_df['Label'].value_counts())\n",
    "        \n",
    "        # Create a MultiDiGraph for this time-slice.\n",
    "        G = nx.MultiDiGraph()\n",
    "\n",
    "        for _, row in slice_df.iterrows():\n",
    "            src_ip = row['Src IP']\n",
    "            dst_ip = row['Dst IP']\n",
    "            \n",
    "            # Convert the label to an int (if missing or invalid, you can decide a fallback; here we assume it is valid)\n",
    "            try:\n",
    "                label = int(row['Label'])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping row due to invalid label: {row['Label']}; error: {e}\")\n",
    "                continue\n",
    "\n",
    "            if pd.isna(src_ip) or pd.isna(dst_ip):\n",
    "                continue\n",
    "\n",
    "            # Add nodes if not already present.\n",
    "            if not G.has_node(src_ip):\n",
    "                G.add_node(src_ip)\n",
    "            if not G.has_node(dst_ip):\n",
    "                G.add_node(dst_ip)\n",
    "\n",
    "            # Add edges for different interactions.\n",
    "            # 1. Network Edge\n",
    "            G.add_edge(src_ip, dst_ip, key='network',\n",
    "                       label=label,\n",
    "                 ######list of selected features####\n",
    "                       interaction='network_communication')\n",
    "\n",
    "            # 2. Context Edge\n",
    "            G.add_edge(src_ip, dst_ip, key='context',\n",
    "                       label=label,\n",
    "             ######list of selected features####\n",
    "                       interaction='context')\n",
    "\n",
    "            # 3. Knowledge Edge\n",
    "            G.add_edge(src_ip, dst_ip, key='knowledge',\n",
    "                       label=label,\n",
    "             ######list of selected features####\n",
    "                       interaction='knowledge')\n",
    "\n",
    "        # Save the graph as a .gpickle file.\n",
    "        graph_path = os.path.join(output_dir, f\"test_graph_hour_{slice_index}.gpickle\")\n",
    "        nx.write_gpickle(G, graph_path)\n",
    "        print(f\"Test graph for hour {slice_index} saved to {graph_path}\")\n",
    "\n",
    "# Usage Example for graph creation\n",
    "if __name__ == \"__main__\":\n",
    "    # Read CSV and prepare DataFrame.\n",
    "    df_test = pd.read_csv('filtered_train_3edge.csv')\n",
    "    df_test['Timestamp'] = pd.to_datetime(df_test['Timestamp'])\n",
    "    # Set Timestamp as index and sort (required for grouping by hour)\n",
    "    df_test = df_test.set_index('Timestamp').sort_index()\n",
    "\n",
    "    output_test_dir = \"3ed_trai_h_graphs\"\n",
    "    create_test_graphs_edge_labels(df_test, output_test_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292af31e-1be8-4f92-9868-4b81c30dc402",
   "metadata": {},
   "source": [
    "# Community detection for graphs and then update the graph with the label of community for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec49d995-452b-40a2-8808-2669078b4658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_14.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_17.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_13.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_18.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_1.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_12.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_11.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_6.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_5.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_4.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_2.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_10.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_16.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_15.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_8.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_20.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_7.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_3.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_0.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_9.gpickle\n",
      "Updated graph with LPA communities and 'x' attribute saved to 3ed_trai_h_graphs_commun/test_graph_hour_19.gpickle\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def detect_and_label_communities_lpa(graph):\n",
    "    \"\"\"\n",
    "    Perform community detection using the Label Propagation Algorithm (LPA) and label nodes with community IDs.\n",
    "    Adds 'x' attribute based on the 'community' label.\n",
    "\n",
    "    Parameters:\n",
    "        graph (nx.MultiDiGraph): Input graph.\n",
    "\n",
    "    Returns:\n",
    "        graph (nx.MultiDiGraph): Updated graph with community labels and 'x' attributes.\n",
    "    \"\"\"\n",
    "    # Convert MultiDiGraph to Graph (undirected graph for LPA)\n",
    "    undirected_graph = nx.Graph(graph)\n",
    "\n",
    "    # Perform community detection using LPA\n",
    "    communities = nx.community.label_propagation_communities(undirected_graph)\n",
    "\n",
    "    # Assign community labels to nodes and add 'x' attribute\n",
    "    for community_id, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            graph.nodes[node]['community'] = community_id\n",
    "            graph.nodes[node]['x'] = [community_id]  # 'x' is a feature; wrap in a list for PyTorch Geometric compatibility\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def process_graphs_with_lpa(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Detect communities using LPA, update graphs with community labels, and add 'x' attribute.\n",
    "    \n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing input graphs.\n",
    "        output_dir (str): Directory to save updated graphs.\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each graph file in the input directory\n",
    "    for graph_file in os.listdir(input_dir):\n",
    "        if not graph_file.endswith('.gpickle'):\n",
    "            continue\n",
    "        \n",
    "        # Load the graph\n",
    "        graph_path = os.path.join(input_dir, graph_file)\n",
    "        G = nx.read_gpickle(graph_path)\n",
    "\n",
    "        # Detect communities using LPA and label nodes\n",
    "        G = detect_and_label_communities_lpa(G)\n",
    "\n",
    "        # Save the updated graph\n",
    "        updated_graph_path = os.path.join(output_dir, graph_file)\n",
    "        nx.write_gpickle(G, updated_graph_path)\n",
    "        print(f\"Updated graph with LPA communities and 'x' attribute saved to {updated_graph_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input directory containing graphs\n",
    "    input_graph_dir = \"3ed_trai_h_graphs\"\n",
    "\n",
    "    # Output directory for updated graphs\n",
    "    output_graph_dir = \"3ed_trai_h_graphs_commun\"\n",
    "\n",
    "    # Process graphs and add community labels using LPA\n",
    "    process_graphs_with_lpa(input_graph_dir, output_graph_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b94df-4577-461d-8009-79255d33c3f2",
   "metadata": {},
   "source": [
    "# convert Multigraph to hetrodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ec10aa-f37a-4a8a-9bfe-219c78a99378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_14.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_17.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_13.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_18.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_1.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_12.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_11.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_6.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_5.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_4.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_2.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_10.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_16.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_15.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_8.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_20.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_7.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_3.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_0.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_9.pt\n",
      "Saved HeteroData with labels to 3ed_trai_h_graphs_hetero_graphs/test_graph_hour_19.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def multiDiGraph_to_hetero_with_label(G: nx.MultiDiGraph) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Converts a MultiDiGraph with multiple edge types to a HeteroData object.\n",
    "    Preserves the 'label' field in data[rel_type].edge_label.\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "    node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    data['ip'].num_nodes = G.number_of_nodes()\n",
    "\n",
    "    # Add node-level features\n",
    "    x = []\n",
    "    community_labels = []\n",
    "    for node in G.nodes():\n",
    "        community = G.nodes[node].get('community', -1)\n",
    "        community_labels.append(community)\n",
    "        x.append([community])\n",
    "    data['ip'].community = torch.tensor(community_labels, dtype=torch.long)\n",
    "    data['ip'].x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "    # Process each edge from G.\n",
    "    for u, v, key, edge_attrs in G.edges(data=True, keys=True):\n",
    "        src = node_mapping[u]\n",
    "        dst = node_mapping[v]\n",
    "        rel_type = ('ip', key, 'ip')\n",
    "        if rel_type not in data.edge_types:\n",
    "            data[rel_type].edge_index = []\n",
    "            data[rel_type].edge_attr = []\n",
    "            data[rel_type].edge_label = []  # Container for the label\n",
    "\n",
    "        data[rel_type].edge_index.append([src, dst])\n",
    "        feature_vec = []\n",
    "        if key == 'network':\n",
    "            for attr_name in [ ######list of selected features####]:\n",
    "                feature_vec.append(edge_attrs.get(attr_name, 0))\n",
    "        elif key == 'context':\n",
    "            for attr_name in [ ######list of selected features####]:\n",
    "                feature_vec.append(edge_attrs.get(attr_name, 0))\n",
    "        elif key == 'knowledge':\n",
    "            for attr_name in [ ######list of selected features####]:\n",
    "                feature_vec.append(edge_attrs.get(attr_name, 0))\n",
    "        data[rel_type].edge_attr.append(feature_vec)\n",
    "        # Save the label—this should now be valid (0 or 1)\n",
    "        data[rel_type].edge_label.append(edge_attrs.get('label', -1))\n",
    "\n",
    "    # Convert lists to tensors.\n",
    "    for rel_type in data.edge_types:\n",
    "        data[rel_type].edge_index = torch.tensor(data[rel_type].edge_index, dtype=torch.long).t().contiguous()\n",
    "        if data[rel_type].edge_attr:\n",
    "            data[rel_type].edge_attr = torch.tensor(data[rel_type].edge_attr, dtype=torch.float)\n",
    "        if data[rel_type].edge_label:\n",
    "            data[rel_type].edge_label = torch.tensor(data[rel_type].edge_label, dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "def process_and_save_hetero_graphs_with_label(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Converts all .gpickle graphs in a directory to HeteroData objects and saves them as .pt,\n",
    "    preserving the 'label' field in data[rel_type].edge_label.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for graph_file in os.listdir(input_dir):\n",
    "        if not graph_file.endswith('.gpickle'):\n",
    "            continue\n",
    "        graph_path = os.path.join(input_dir, graph_file)\n",
    "        G = nx.read_gpickle(graph_path)\n",
    "        hetero_data = multiDiGraph_to_hetero_with_label(G)\n",
    "        hetero_path = os.path.join(output_dir, graph_file.replace('.gpickle', '.pt'))\n",
    "        torch.save(hetero_data, hetero_path)\n",
    "        print(f\"Saved HeteroData with labels to {hetero_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_test_dir = \"3ed_trai_h_graphs_commun\"         # Input .gpickle files (with communities added)\n",
    "    output_test_pt_dir = \"3ed_trai_h_graphs_hetero_graphs\" # Output .pt files\n",
    "    process_and_save_hetero_graphs_with_label(input_test_dir, output_test_pt_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76908e54-ad5c-4a56-beb1-949dc30cc2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AnomalyDetection)",
   "language": "python",
   "name": "anomalydetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
